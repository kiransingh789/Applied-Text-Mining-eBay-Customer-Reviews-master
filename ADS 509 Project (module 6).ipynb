{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product 1: Texas Instruments TI-83 Plus Graphing Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialzing df\n",
    "eBay_1 = []\n",
    "eBay_1 = pd.DataFrame(eBay_1)\n",
    "\n",
    "# initilazing lists\n",
    "stars = []\n",
    "content = []\n",
    "titles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting page base and making list of links to the reviews\n",
    "\n",
    "page_base = 'https://www.ebay.com/urw/Texas-Instruments-TI-83-Plus-Graphing-Calculator/product-reviews/54847886?condition=all&pgn='\n",
    "total_pages = 208\n",
    "links = []\n",
    "\n",
    "for link in range(1,total_pages):\n",
    "    links.append(page_base+str(link))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially, we pulled the links directly through the html and looped through, but the initial page only provided the first 7 pages of reviews. This was the easiest way around this issue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling lists with data from Web Scrape\n",
    "\n",
    "for page in links:\n",
    "    \n",
    "    r = requests.get(page)\n",
    "    #time.sleep(1)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    \n",
    "    for star in soup.find_all('div', class_='ebay-review-section-l'): \n",
    "        stars.append(star.find('span','star-rating')['aria-label'])\n",
    "        \n",
    "    for review_content in soup.find_all('p', class_ = 'review-item-content rvw-wrap-spaces'): \n",
    "        content.append(review_content.text)\n",
    "    \n",
    "    for review_title in soup.find_all('h3', class_ = 'review-item-title rvw-nowrap-spaces'): \n",
    "        titles.append(review_title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting list into Data Frame\n",
    "\n",
    "eBay_1['Review Title'] = titles\n",
    "#eBay['Review Content'] = content\n",
    "eBay_1['Stars'] = stars\n",
    "eBay_1['Item'] = 'Texas Instruments TI-83 Plus Graphing Calculator'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A user must include a title in their review, but content is not needed. This creates a different amount of content items than titles and stars. This results in us having to use titles as our source of text, as there is no way to know which reviews have content in their review or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product 2: Apple AirPods Pro Left Airpod OEM Left Side Airpods Pro Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialzing df\n",
    "eBay_2 = []\n",
    "eBay_2 = pd.DataFrame(eBay_2)\n",
    "\n",
    "# initilazing lists\n",
    "stars = []\n",
    "titles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting page base and making list of links to the reviews\n",
    "\n",
    "page_base = 'https://www.ebay.com/urw/Apple-AirPods-Pro-Wireless-In-Ear-Headsets-White/product-reviews/10034976643?_itm=115149763582&pgn='\n",
    "total_pages = 230\n",
    "links = []\n",
    "\n",
    "for link in range(1,total_pages):\n",
    "    links.append(page_base+str(link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling lists with data from Web Scrape\n",
    "\n",
    "for page in links:\n",
    "    \n",
    "    r = requests.get(page)\n",
    "    #time.sleep(1)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    \n",
    "    for star in soup.find_all('div', class_='ebay-review-section-l'): \n",
    "        stars.append(star.find('span','star-rating')['aria-label'])\n",
    "    \n",
    "    for review_title in soup.find_all('h3', class_ = 'review-item-title rvw-nowrap-spaces'): \n",
    "        titles.append(review_title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting list into Data Frame\n",
    "\n",
    "eBay_2['Review Title'] = titles\n",
    "eBay_2['Stars'] = stars\n",
    "eBay_2['Item'] = 'Apple AirPods Pro Left Airpod OEM Left Side Airpods Pro Only'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product 3: Sony PS5 Console w/ Blu-Ray Disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialzing df\n",
    "eBay_3 = []\n",
    "eBay_3 = pd.DataFrame(eBay_3)\n",
    "\n",
    "# initilazing lists\n",
    "stars = []\n",
    "titles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting page base and making list of links to the reviews\n",
    "\n",
    "page_base = 'https://www.ebay.com/urw/Sony-PS5-Blu-Ray-Edition-Console-White/product-reviews/19040936896?_itm=265175892133&pgn='\n",
    "total_pages = 194\n",
    "links = []\n",
    "\n",
    "for link in range(1,total_pages):\n",
    "    links.append(page_base+str(link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling lists with data from Web Scrape\n",
    "\n",
    "for page in links:\n",
    "    \n",
    "    r = requests.get(page)\n",
    "    # time.sleep(1)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    \n",
    "    for star in soup.find_all('div', class_='ebay-review-section-l'): \n",
    "        stars.append(star.find('span','star-rating')['aria-label'])\n",
    "    \n",
    "    for review_title in soup.find_all('h3', class_ = 'review-item-title rvw-nowrap-spaces'): \n",
    "        titles.append(review_title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting list into Data Frame\n",
    "\n",
    "eBay_3['Review Title'] = titles\n",
    "eBay_3['Stars'] = stars\n",
    "eBay_3['Item'] = 'Sony PS5 Console w/ Blu-Ray Disc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product 4: Super Bright 90000LM LED Tactical Flashlight Zoomable With Rechargeable Battery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialzing df\n",
    "eBay_4 = []\n",
    "eBay_4 = pd.DataFrame(eBay_4)\n",
    "\n",
    "# initilazing lists\n",
    "stars = []\n",
    "titles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting page base and making list of links to the reviews\n",
    "\n",
    "page_base = 'https://www.ebay.com/urw/Garberiel-AF20171221-8000-Lumens-Tactical-Flashlight-With-Rechargeable-Battery/product-reviews/4041786004?_itm=393096143620&pgn='\n",
    "total_pages = 41\n",
    "links = []\n",
    "\n",
    "for link in range(1,total_pages):\n",
    "    links.append(page_base+str(link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling lists with data from Web Scrape\n",
    "\n",
    "for page in links:\n",
    "    \n",
    "    r = requests.get(page)\n",
    "    #time.sleep(1)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    \n",
    "    for star in soup.find_all('div', class_='ebay-review-section-l'): \n",
    "        stars.append(star.find('span','star-rating')['aria-label'])\n",
    "    \n",
    "    for review_title in soup.find_all('h3', class_ = 'review-item-title rvw-nowrap-spaces'): \n",
    "        titles.append(review_title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting list into Data Frame\n",
    "\n",
    "eBay_4['Review Title'] = titles\n",
    "eBay_4['Stars'] = stars\n",
    "eBay_4['Item'] = 'Super Bright 90000LM LED Tactical Flashlight Zoomable With Rechargeable Battery'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Product 5: Canon PIXMA MG2520 All-In-One Inkjet Printer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialzing df\n",
    "eBay_5 = []\n",
    "eBay_5 = pd.DataFrame(eBay_5)\n",
    "\n",
    "# initilazing lists\n",
    "stars = []\n",
    "titles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting page base and making list of links to the reviews\n",
    "\n",
    "page_base = 'https://www.ebay.com/urw/Canon-PIXMA-MG2520-All-In-One-Inkjet-Printer/product-reviews/182754283?pgn='\n",
    "total_pages = 42\n",
    "links = []\n",
    "\n",
    "for link in range(1,total_pages):\n",
    "    links.append(page_base+str(link))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling lists with data from Web Scrape\n",
    "\n",
    "for page in links:\n",
    "    \n",
    "    r = requests.get(page)\n",
    "    # time.sleep(1)\n",
    "    soup = BeautifulSoup(r.text, 'html.parser')\n",
    "    \n",
    "    for star in soup.find_all('div', class_='ebay-review-section-l'): \n",
    "        stars.append(star.find('span','star-rating')['aria-label'])\n",
    "    \n",
    "    for review_title in soup.find_all('h3', class_ = 'review-item-title rvw-nowrap-spaces'): \n",
    "        titles.append(review_title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting list into Data Frame\n",
    "\n",
    "eBay_5['Review Title'] = titles\n",
    "eBay_5['Stars'] = stars\n",
    "eBay_5['Item'] = 'Canon PIXMA MG2520 All-In-One Inkjet Printer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining data to get one data frame\n",
    "\n",
    "eBay = pd.concat([eBay_1, eBay_2, eBay_3, eBay_4, eBay_5], ignore_index=True)\n",
    "eBay.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binning reviews for predictive modeling \n",
    "\n",
    "is_positive = []\n",
    "\n",
    "for stars in eBay['Stars']:\n",
    "    if stars == '5 stars' or stars == '4 stars':\n",
    "        is_positive.append(1)\n",
    "    else:\n",
    "        is_positive.append(0)\n",
    "        \n",
    "eBay['Is_Positive?'] = is_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Title</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Item</th>\n",
       "      <th>Is_Positive?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nice item- as we used to say: \"Works fine, las...</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Texas Instruments TI-83 Plus Graphing Calculator</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cheap</td>\n",
       "      <td>3 stars</td>\n",
       "      <td>Texas Instruments TI-83 Plus Graphing Calculator</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Texas Instruments TI-83 Plus Graphic Calculator</td>\n",
       "      <td>4 stars</td>\n",
       "      <td>Texas Instruments TI-83 Plus Graphing Calculator</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TI-83</td>\n",
       "      <td>4 stars</td>\n",
       "      <td>Texas Instruments TI-83 Plus Graphing Calculator</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Handy calculator, solid and functional</td>\n",
       "      <td>4 stars</td>\n",
       "      <td>Texas Instruments TI-83 Plus Graphing Calculator</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7098</th>\n",
       "      <td>is so so</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Canon PIXMA MG2520 All-In-One Inkjet Printer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7099</th>\n",
       "      <td>Nice printer great price</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Canon PIXMA MG2520 All-In-One Inkjet Printer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7100</th>\n",
       "      <td>like it</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Canon PIXMA MG2520 All-In-One Inkjet Printer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7101</th>\n",
       "      <td>PERFECT</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Canon PIXMA MG2520 All-In-One Inkjet Printer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7102</th>\n",
       "      <td>Excelente</td>\n",
       "      <td>5 stars</td>\n",
       "      <td>Canon PIXMA MG2520 All-In-One Inkjet Printer</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7103 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Review Title    Stars  \\\n",
       "0     Nice item- as we used to say: \"Works fine, las...  5 stars   \n",
       "1                                                 Cheap  3 stars   \n",
       "2       Texas Instruments TI-83 Plus Graphic Calculator  4 stars   \n",
       "3                                                 TI-83  4 stars   \n",
       "4                Handy calculator, solid and functional  4 stars   \n",
       "...                                                 ...      ...   \n",
       "7098                                           is so so  5 stars   \n",
       "7099                          Nice printer great price   5 stars   \n",
       "7100                                            like it  5 stars   \n",
       "7101                                            PERFECT  5 stars   \n",
       "7102                                          Excelente  5 stars   \n",
       "\n",
       "                                                  Item  Is_Positive?  \n",
       "0     Texas Instruments TI-83 Plus Graphing Calculator             1  \n",
       "1     Texas Instruments TI-83 Plus Graphing Calculator             0  \n",
       "2     Texas Instruments TI-83 Plus Graphing Calculator             1  \n",
       "3     Texas Instruments TI-83 Plus Graphing Calculator             1  \n",
       "4     Texas Instruments TI-83 Plus Graphing Calculator             1  \n",
       "...                                                ...           ...  \n",
       "7098      Canon PIXMA MG2520 All-In-One Inkjet Printer             1  \n",
       "7099      Canon PIXMA MG2520 All-In-One Inkjet Printer             1  \n",
       "7100      Canon PIXMA MG2520 All-In-One Inkjet Printer             1  \n",
       "7101      Canon PIXMA MG2520 All-In-One Inkjet Printer             1  \n",
       "7102      Canon PIXMA MG2520 All-In-One Inkjet Printer             1  \n",
       "\n",
       "[7103 rows x 4 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What the final dataframe looks like\n",
    "\n",
    "eBay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Descriptive Statistics on the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "# Some punctuation variations\n",
    "punctuation = set(punctuation) # speeds up comparison\n",
    "tw_punct = punctuation - {\"#\"}\n",
    "\n",
    "# Stopwords\n",
    "sw = stopwords.words(\"english\")\n",
    "\n",
    "# Two useful regex\n",
    "whitespace_pattern = re.compile(r\"\\s+\")\n",
    "hashtag_pattern = re.compile(r\"^#[0-9a-zA-Z]+\")\n",
    "\n",
    "# full set of emojis\n",
    "all_language_emojis = set()\n",
    "\n",
    "for country in emoji.UNICODE_EMOJI : \n",
    "    for em in emoji.UNICODE_EMOJI[country] : \n",
    "        all_language_emojis.add(em)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate descriptive stats\n",
    "\n",
    "def descriptive_stats(tokens, num_tokens = 5, verbose=True) :\n",
    "    \"\"\"\n",
    "        Given a list of tokens, print number of tokens, number of unique tokens, \n",
    "        number of characters, lexical diversity (https://en.wikipedia.org/wiki/Lexical_diversity), \n",
    "        and num_tokens most common tokens. Return a list with the number of tokens, number\n",
    "        of unique tokens, lexical diversity, and number of characters. \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    # Fill in the correct values here.\n",
    "    tokes = tokens.split()\n",
    "    num_tokens = sum(map(len, (s.split() for s in tokes)))\n",
    "    num_unique_tokens = len(set(w.lower() for w in tokes))\n",
    "    lexical_diversity = num_unique_tokens / num_tokens\n",
    "    num_characters = sum(list(map(len, tokes)))\n",
    "    \n",
    "    if verbose :        \n",
    "        print(f\"There are {num_tokens} tokens in the data.\")\n",
    "        print(f\"There are {num_unique_tokens} unique tokens in the data.\")\n",
    "        print(f\"There are {num_characters} characters in the data.\")\n",
    "        print(f\"The lexical diversity is {lexical_diversity:.3f} in the data.\")\n",
    "    \n",
    "        # print the five most common tokens\n",
    "        \n",
    "    return([num_tokens, num_unique_tokens,\n",
    "            lexical_diversity,\n",
    "            num_characters])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#other useful functions from previous modules\n",
    "def is_emoji(s):\n",
    "    return(s in all_language_emojis)\n",
    "\n",
    "def contains_emoji(s):\n",
    "    \n",
    "    s = str(s)\n",
    "    emojis = [ch for ch in s if is_emoji(ch)]\n",
    "\n",
    "    return(len(emojis) > 0)\n",
    "\n",
    "\n",
    "def remove_stop(tokens) :\n",
    "    # modify this function to remove stopwords\n",
    "    tokens_wo_sw = []\n",
    "    for w in tokens:\n",
    "        if w.lower() not in sw:\n",
    "            tokens_wo_sw.append(w)\n",
    "    return(tokens_wo_sw)\n",
    " \n",
    "def remove_punctuation(text, punct_set=tw_punct): \n",
    "    for ele in text:\n",
    "        if ele in punct_set:\n",
    "            text = text.replace(ele, \"\")\n",
    "    return(text)\n",
    "\n",
    "def tokenize(text) : \n",
    "    \"\"\" Splitting on whitespace rather than the book's tokenize function. That \n",
    "        function will drop tokens like '#hashtag' or '2A', which we need for Twitter. \"\"\"\n",
    "    \n",
    "    # modify this function to return tokens\n",
    "    text = text.split()\n",
    "    return(text)\n",
    "\n",
    "def prepare(text, pipeline) : \n",
    "    tokens = str(text)\n",
    "    \n",
    "    for transform in pipeline : \n",
    "        tokens = transform(tokens)\n",
    "        \n",
    "    return(tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and Tokenize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipeline = [str.lower, remove_punctuation, tokenize, remove_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_eBay = []\n",
    "\n",
    "for review in range(len(eBay)):\n",
    "    temp = prepare(eBay['Review Title'][review], my_pipeline)\n",
    "    clean_eBay.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Descriptive_Stats on our Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 16880 tokens in the data.\n",
      "There are 3480 unique tokens in the data.\n",
      "There are 160628 characters in the data.\n",
      "The lexical diversity is 0.206 in the data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[16880, 3480, 0.20616113744075829, 160628]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptive_stats(str(clean_eBay), verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading DataFrame into CSV\n",
    "\n",
    "eBay.to_csv('C:/Users/mzazu/OneDrive/Documents/USD papers/509/eBay.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
